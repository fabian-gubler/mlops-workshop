{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training ðŸ› \n",
    "\n",
    "Let's create a model that can predict the generated power, given the wind speed. <br>\n",
    "In this notebook we use the package `scikit-learn` to prepare the data and train a model. <br>\n",
    "We say *train*, but for now, we'll actually just be *fitting* a linear regression model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/turbine-data.csv\"\n",
    "data = pd.read_csv(data_path).set_index(\"timestamp\")\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some quick preparation of the data, before we train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data with missing values\n",
    "data_without_na = data.dropna() \n",
    "\n",
    "X = data_without_na[[\"wind_speed\"]]  # Our model's input\n",
    "y = data_without_na[\"active_power\"]  # Target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out a test set which the model will not see during training, \n",
    "# so we can evaluate the model's performance on unseen data.\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    shuffle=False,\n",
    "    # use (only) 10% of all data for training\n",
    "    train_size=0.1  # don't change this number\n",
    ")\n",
    "print(f\"Training data: from {X_train.index.min()} to {X_train.index.max()}\")\n",
    "print(f\"Testing data: from {X_test.index.min()} to {X_test.index.max()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a model. Here we start small with a linear regression model. In the next notebook exercise you may make this model as fancy as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.linear_model.LinearRegression(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "# score = model.score(X_train, y_train)\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! <br>\n",
    "Or... is it?\n",
    "\n",
    "First of all, what does `score()` actually compute? You can use the following code cell to find out. What's better, a higher or lower score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model.steps[-1][1].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second of all, how do we know if this is *good* compared to other runs for this dataset, or compared to the models of your neighbours?\n",
    "\n",
    "Let's find out how we can track these experiments better in the next excercise, and learn how experiment tracking improves the MLOps workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
